<img src="./assets/icon.png" width="18" alt="Switch between English and Chinese"> English | [简体中文](./README.zh-CN.md)
# Chart2Vec:  A Universal Embedding of Context-Aware Visualizations

Chart2Vec is a chart embedding model in the visualization domain for transforming visual charts directly into vectors. The vectors generated by this model not only contain effective information about the individual charts themselves, but also cover the contextual relationships between the charts. "Context" refers to the adjacency of charts, which is usually present in multiple view visualizations (dashboards, data stories, etc.) Chart2Vec can be stored and computed as a new data format and applied to a variety of downstream tasks of the visualization: visual recommendation, clustering, interpolation, and so on.

<div align=center>
    <img src="assets/model_architecture.png" width="50%" align="middle">
    <div>Chart2Vec model</div>
</div>

Chart2Vec consists of two core modules: Input embedding and Encoder. The repository contains the core code of Chart2Vec model, and the main functions of each folder/file are as follows:

* **_dataset/_**: training and testing data.
* **_input embedding/_**: represent the chart fact data as initial vectors.
* **_encoder/_**: further encoding of the initial vectors of the charts, integrating both structural and semantic information.
* **_utils/_**:  data loading methods, constant definitions, and some helper code.
* **_train.py_**: code for training the model.
* **_test.py_**: inference code for the model.
* **_evaluate.py_**: model validation code.

## dataset

The _dataset/_ folder contains mainly the training dataset and testing dataset of the model, which are derived from the data storytelling platform [Calliope](https://datacalliope.com/) and [Tableau Public](https://public.tableau.com/)

* **_training_data.json_**: The training dataset for the model contains 42,222 training samples. Each training sample consists of 4 visualizations, the first three being visualizations that are connected in sequence to the same data story/dashboard, and the fourth being a negative example (not in the same data story/dashboard as the first three charts).
* **_testing_data.json_**: The testing dataset for the model contains 560 test samples. Each sample is declarative syntax data for a single chart visualization, where each chart is identified by fact_id and consists of three numbers, e.g., "281-816-1" means dataset #281 - data story/dashboard #816 - visualization #1.
* **_story_stopwords.txt_**: Stop words list.

**Note**：We use chart fact as the initial format for a single visualization, which consists of 7 tuples：chart fact={fact_type, chart_type, subspace, breakdown, measure, focus, meta}，some of these field definitions are derived from [Calliope](https://ieeexplore.ieee.org/document/9222368). The 7 tuples are explained in detail in the following table: 
|  Property   | Type  | Description |
|  ----  | ----  | ----  |
| fact_type  | String | Data fact type, with 10 options: `"trend"`, `"categorization"`, `"value"`, `"difference"`, `"distribution"`, `"proportion"`, `"rank"`, `"extreme"`, `"outlier"`, `"association"` |
| chart_type  | String | Chart type, with 18 options: `"Vertical Bar Chart"`, `"Pie Chart"`, `"Progress Bar Chart"`, `"Treemap"`, `"Line Chart"`, `"Text Chart"`, `"Area Chart"`, `"Horizontal Bar Chart"`, `"Proportion Isotype Chart"`, `"Scatter Plot"`, `"Color Filling Map"`, `"Bubble Chart"`, `"Ring Chart"`, `"Bubblemap"`, `"Isotype Bar Chart"`, `"Table"`, `"Network"`, `"Radar Chart"`  |
| subspace  | Object[] | Consists of a set of filters to filter the data range. |
| breakdown  | Object[] | consists of a set of array fields of temporal or categorical type, further dividing the data items of the subspace into groups. |
| measure  | Object[] | Numeric data fields that can be combined with different aggregation methods to further measure the data in the grouping |
| focus  | Object[] | Data item or data group requiring attention. |
| meta  | [] \| "" | Additional information about the chart, which varies according to fact type. |

## input_embedding and encoder

* **_input_embedding/semantic_extract.py_**: From the original chart data chart fact extract semantic information, i.e., extract the words with actual meaning, carry out word division, remove the deactivated words and then uniformly stored in an array.
* **_input_embedding/structual_extract.py_**: The structural information is extracted from the raw chart data chart fact and represented as a matrix of one-hot vectors.
* **_input_embedding/structual_rules.txt_**: The full set of rule information that can be extracted from chart fact.
* **_encoder/modeling_chart2vec.py_**: Chart2Vec core network structure for fusion of semantic and structural information of charts.

<div align=center>
    <img src="assets/model_chart_format.png" width="100%" align="middle">
    <div>Structural and semantic information in chart fact</div>
</div>

## Chart2Vec model

You can download our Chart2Vec model and adopt the code in that repository for loading and using the model: [Chart2Vec](download).

## Usage

* **_train.py_**: To train the model, you can directly run the train.py code, the following is the sample code.

```python
# Multi-task Loss Function
loss_fc = ImprovedQuadrupletLoss().to(device)
chart_emb = Chart2Vec().to(device)
for i in range(epochs):
    total_loss = 0.0
    for j in range(batch_num):
        # struct_one_hot_x1 for structural information, semantic_tokens_x1, semantic_pos_x1 for semantic information
        res_chart_x1 = chart_emb(struct_one_hot_x1, semantic_tokens_x1, semantic_pos_x1)
        res_chart_x2 = chart_emb(struct_one_hot_x2, semantic_tokens_x2, semantic_pos_x2)
        res_chart_x3 = chart_emb(struct_one_hot_x3, semantic_tokens_x3, semantic_pos_x3)
        res_chart_y1 = chart_emb(struct_one_hot_y1, semantic_tokens_y1, semantic_pos_y1)
        chart2vec_loss = loss_fc(res_chart_x1,  res_chart_x2, res_chart_x3, res_chart_y1)
        total_loss += chart2vec_loss.cpu().item()
        chart2vec_loss.backward()
        optimizer.step()
        chart_emb.zero_grad()
```

* **_test.py_**: The model's inference represents each individual chart in dataset/testing_data.json as a 300-dimensional vector, as shown in the following example code.

```python
model_path = "chart2vec_base.pth"
chart2vec_model = Chart2Vec().to(device)
state_dict = torch.load(model_save_path, map_location=torch.device(device))
chart2vec_model.load_state_dict(state_dict["model"])
chart2vec_model.eval()
output_vec = chart2vec_model(struct_one_hot, semantic_tokens, semantic_pos)
```

* **_evaluate.py_**: For model evaluation, we measure the ability of Chart2Vec embedding using three metrics: top-2 retrieval accuracy, top-3 retrieval accuracy, and co-occurrence, respectively, to evaluate whether it can effectively capture the contextual relationships among multiple charts.

  * **top-2 retrieval accuracy**. For anchored charts, the chart represented by the closest vector is searched for based on the distance between chart vectors, and if two charts originate from a unified data story and are spaced within 2 of each other, the anchored chart is compliant for this metric.Calculate all results for the test set of 560 charts and divide the number of charts that are compliant by the total number of charts for the final value.
  * **top-3 retrieval accuracy**.  Similar to the calculation of top-2 retrieval accuracy, an anchored chart is compliant on this metric if the retrieved chart and the anchored chart originate from a uniform data story and are spaced within 3 of each other.
  * **co-occurrence**. If the retrieved chart and the anchor chart originate from a unified data story, the anchor chart is compliant on co-occurrence.The final value of the metric can be obtained by counting the number of all eligible charts and dividing by the total number.


```python
# Each individual chart in the test dataset is represented as a vectorized posterior
path_name="results/testing_data_vectors.json"
# Search for the nearest 1 for the selected charts.
evaluate_more_nearest_dis_triplets(path_name,search_num=1)
```